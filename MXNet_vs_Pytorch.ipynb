{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MXNet vs Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN02eqeFJa7C",
        "colab_type": "code",
        "outputId": "02168ea7-f4d6-4fd8-b0a5-027b95f1c912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install mxnet-cu100\n",
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwXOrO0eaMv8",
        "colab_type": "code",
        "outputId": "93340c90-e2de-4803-8307-8f3220f5d989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import mxnet as mx\n",
        "import mxnet.gluon.nn as mxnn\n",
        "from mxnet import nd\n",
        "from mxnet import gluon, autograd\n",
        "from mxnet.gluon.data.vision import transforms as mxT\n",
        "import time, os, shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as pytorchnn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as pytorchT\n",
        "from torch import optim as pytorchoptim\n",
        "from torch.backends import cudnn\n",
        "\n",
        "cudnn.benchmark = True\n",
        "ctx = mx.gpu()\n",
        "\n",
        "print(mx.__version__)\n",
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.1\n",
            "1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXZB3YvGIOMm",
        "colab_type": "text"
      },
      "source": [
        "#Builiding MXNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlGxrTEtKBPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mx_conv3x3(out_planes, stride=1):\n",
        "    \" 3x3 convolution with padding \"\n",
        "    return mxnn.Conv2D(out_planes, kernel_size=3, strides=stride, padding=1)\n",
        "\n",
        "\n",
        "class mxBasicBlock(mxnn.HybridBlock):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, planes, stride=1, downsample=None, **kwargs):\n",
        "        super(mxBasicBlock, self).__init__(**kwargs)\n",
        "        self.conv1 = mx_conv3x3(planes, stride)\n",
        "        self.bn1 = mxnn.BatchNorm()\n",
        "        self.conv2 = mx_conv3x3(planes)\n",
        "        self.bn2 = mxnn.BatchNorm()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out = F.relu(residual + out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class mxResNet_Cifar(mxnn.HybridBlock):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10, **kwargs):\n",
        "        super(mxResNet_Cifar, self).__init__(**kwargs)\n",
        "\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = mxnn.Conv2D(\n",
        "            16, kernel_size=3, strides=1, padding=1)\n",
        "        self.bn1 = mxnn.BatchNorm()\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = mxnn.AvgPool2D(8, strides=1)\n",
        "        self.fc = mxnn.Dense(num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = mxnn.HybridSequential()\n",
        "            downsample.add(\n",
        "                mxnn.Conv2D(planes * block.expansion,\n",
        "                          kernel_size=1, strides=stride)\n",
        "            )\n",
        "\n",
        "        layers = mxnn.HybridSequential()\n",
        "        layers.add(block(planes, stride, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.add(block(planes))\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def mx_resnet20_cifar(**kwargs):\n",
        "    model = mxResNet_Cifar(mxBasicBlock, [3, 3, 3], **kwargs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-8m3jjSQ_tB",
        "colab_type": "code",
        "outputId": "fac605b0-aab4-4b22-eec8-185044b7ba7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "mxnet = mx_resnet20_cifar()\n",
        "mxnet.initialize(ctx = ctx)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.24 s, sys: 575 ms, total: 1.82 s\n",
            "Wall time: 1.81 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UCmHRrcRNMx",
        "colab_type": "code",
        "outputId": "78528002-a7ba-4099-9edc-60e4f35a06ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = nd.ones((1000, 3, 32, 32))\n",
        "x.shape, x.dtype"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 3, 32, 32), numpy.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIeT_B7FKBmA",
        "colab_type": "code",
        "outputId": "7a072abf-c9c1-463a-9c9b-37a155f6a241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "%%time\n",
        "#before hybridization\n",
        "mxnet(x.as_in_context(mx.gpu()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 110 ms, sys: 51.7 ms, total: 161 ms\n",
            "Wall time: 102 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " ...\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]]\n",
              "<NDArray 1000x10 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjXm5XFmWzWr",
        "colab_type": "text"
      },
      "source": [
        "###The above cell took 88.7ms to run, that's quit a lot of time run such a simple program. This is happening because mxnet model first initialize its parameters at the first run and then do the further computaion. But if you run the same cell again as below you'll see better performance becuse now mxnet model has already initialized its parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-E02PANXdZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9b9d8a1c-39e0-4afd-d1e1-e17ec56397d3"
      },
      "source": [
        "%%time\n",
        "#before hybridization\n",
        "mxnet(x.as_in_context(mx.gpu()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13.2 ms, sys: 4.68 ms, total: 17.9 ms\n",
            "Wall time: 13 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " ...\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]]\n",
              "<NDArray 1000x10 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlZJzG9DX41G",
        "colab_type": "text"
      },
      "source": [
        "###So after initialization the final time taken by unhybridized mxnet model is 17.9 ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrY4OUDpXlxr",
        "colab_type": "text"
      },
      "source": [
        "###Hybridizing converts mxnet dynamic model to static."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fCvrinjK-x1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mxnet.hybridize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6k68iJSKBys",
        "colab_type": "code",
        "outputId": "f0735e3b-61cf-4737-9725-8f683b545445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "%%time\n",
        "#after hybridization\n",
        "mxnet(x.as_in_context(mx.gpu()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.4 ms, sys: 2.05 ms, total: 17.4 ms\n",
            "Wall time: 18 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " ...\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]]\n",
              "<NDArray 1000x10 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5tOFtU_Xzy5",
        "colab_type": "text"
      },
      "source": [
        "###The above cell took alomst 20.2 ms to run. But if you run the same cell again as below you'll see better performance becuse now mxnet model has already initialized its parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g85aOnPnYMn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "5b90abc9-c898-4f6a-c3a2-b72f329eeb60"
      },
      "source": [
        "%%time\n",
        "#after hybridization\n",
        "mxnet(x.as_in_context(mx.gpu()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.23 ms, sys: 124 µs, total: 6.35 ms\n",
            "Wall time: 5.1 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " ...\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]\n",
              " [ 0.00054889 -0.00041725 -0.00197463 ... -0.00700838 -0.00223936\n",
              "  -0.00076538]]\n",
              "<NDArray 1000x10 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le0DlQXCYP_K",
        "colab_type": "text"
      },
      "source": [
        "###So you see after hydridizing the model took 3.2 ms while before the model took 17.9 ms. That's a massive 5x performance boost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mJ7f6UqIyxj",
        "colab_type": "text"
      },
      "source": [
        "#Building Pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kew52lbMbxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def torch_conv3x3(in_planes, out_planes, stride=1):\n",
        "    \" 3x3 convolution with padding \"\n",
        "    return pytorchnn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1)\n",
        "\n",
        "\n",
        "class pytorchBasicBlock(pytorchnn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(pytorchBasicBlock, self).__init__()\n",
        "        self.conv1 = torch_conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = pytorchnn.BatchNorm2d(planes)\n",
        "        self.relu = pytorchnn.ReLU(inplace=True)\n",
        "        self.conv2 = torch_conv3x3(planes, planes)\n",
        "        self.bn2 = pytorchnn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class pytorchResNet_Cifar(pytorchnn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(pytorchResNet_Cifar, self).__init__()\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = pytorchnn.Conv2d(3, 16, kernel_size=3,\n",
        "                               stride=1, padding=1)\n",
        "        self.bn1 = pytorchnn.BatchNorm2d(16)\n",
        "        self.relu = pytorchnn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = pytorchnn.AvgPool2d(8, stride=1)\n",
        "        self.fc = pytorchnn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, pytorchnn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, pytorchnn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = pytorchnn.Sequential(\n",
        "                pytorchnn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride),\n",
        "                pytorchnn.BatchNorm2d(planes * block.expansion)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return pytorchnn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def pytorch_resnet20_cifar(**kwargs):\n",
        "    model = pytorchResNet_Cifar(pytorchBasicBlock, [3, 3, 3], **kwargs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drcG5GsiRk6X",
        "colab_type": "code",
        "outputId": "43ec4e1c-5b65-4067-900e-4bb4b10d1eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "pytorch = pytorch_resnet20_cifar()\n",
        "pytorch.cuda()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.87 s, sys: 632 ms, total: 2.5 s\n",
            "Wall time: 2.51 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J4sHe6-Rke3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.ones((1000, 3, 32, 32), dtype = torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJY1zX5BTTKH",
        "colab_type": "code",
        "outputId": "5fe291ad-3e04-4435-f7a4-2c2227422636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "%%time\n",
        "pytorch(x.cuda())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 30.2 ms, sys: 313 ms, total: 343 ms\n",
            "Wall time: 703 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        ...,\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_TJ3JgcYzY1",
        "colab_type": "text"
      },
      "source": [
        "###As you can see above pytorch took 832 ms. That is again beacuse of some internal initialization that occurs when you pass a value to your model first time. So I am gonna run above cell again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzB53D-xZOeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f240ae7a-78da-47ee-e15b-c241b385d0e9"
      },
      "source": [
        "%%time\n",
        "pytorch(x.cuda())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.5 ms, sys: 8.28 ms, total: 23.8 ms\n",
            "Wall time: 25.6 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        ...,\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421],\n",
              "        [ 0.3616, -0.3197, -1.3828,  ...,  0.2917,  0.0053, -0.8421]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxDM8AtNZQQa",
        "colab_type": "text"
      },
      "source": [
        "###So we can see that pytorch performance has improved and now its 28 ms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3KyLh0za_E1",
        "colab_type": "text"
      },
      "source": [
        "###We can already see that MXNet's model(3.2 ms) is faster than Pytorch's model(28 ms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d-r8hxlUB5Y",
        "colab_type": "text"
      },
      "source": [
        "#Training MXNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypmddEk5bl8q",
        "colab_type": "text"
      },
      "source": [
        "##Getting Dataset and Data loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aepgbtPZTvkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = mxT.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_transfrom = mxT.Compose([\n",
        "    mxT.RandomFlipLeftRight(),\n",
        "    mxT.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "val_transform = mxT.Compose([\n",
        "    mxT.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "mxtrainset = gluon.data.vision.datasets.CIFAR10(\n",
        "    './data', train=True).transform_first(train_transfrom)\n",
        "mxtrainloader = gluon.data.DataLoader(\n",
        "    mxtrainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "mxtestset = gluon.data.vision.datasets.CIFAR10(\n",
        "    './data', train=False).transform_first(val_transform)\n",
        "mxtestloader = gluon.data.DataLoader(\n",
        "    mxtestset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "916UqeY7Tvb4",
        "colab_type": "code",
        "outputId": "c35ba658-e090-4421-ee76-52d3d7addc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "mxobjective = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "mxoptimizer = gluon.Trainer(mxnet.collect_params(), 'adam', {'learning_rate': 0.001})"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.7 ms, sys: 841 µs, total: 4.54 ms\n",
            "Wall time: 4.78 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEwjDteLTvM_",
        "colab_type": "code",
        "outputId": "1ec19b9c-bb47-4e5a-8d00-d413374fb92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(10):\n",
        "    for features, labels in mxtrainloader:\n",
        "        with autograd.record():\n",
        "            output = mxnet(features.as_in_context(ctx))\n",
        "            loss = mxobjective(output, labels.as_in_context(ctx))\n",
        "        loss.backward()\n",
        "        mxoptimizer.step(batch_size)\n",
        "    print('Epoch:', epoch, 'done.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 done.\n",
            "Epoch: 1 done.\n",
            "Epoch: 2 done.\n",
            "Epoch: 3 done.\n",
            "Epoch: 4 done.\n",
            "Epoch: 5 done.\n",
            "Epoch: 6 done.\n",
            "Epoch: 7 done.\n",
            "Epoch: 8 done.\n",
            "Epoch: 9 done.\n",
            "CPU times: user 2min 30s, sys: 46.4 s, total: 3min 16s\n",
            "Wall time: 2min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S5u_fVHTvUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metric = mx.metric.Accuracy()\n",
        "metric.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHJyrb2DTvFA",
        "colab_type": "code",
        "outputId": "405d06d7-224c-4fd2-d3a3-848c24458719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "for features, labels in mxtestloader:\n",
        "    output = mxnet(features.as_in_context(ctx))\n",
        "    metric.update(labels.as_in_context(ctx), output)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.46 s, sys: 824 ms, total: 2.29 s\n",
            "Wall time: 2.87 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA3EP103dOy1",
        "colab_type": "code",
        "outputId": "8372d618-4bd1-4f98-92ce-6d66ea535171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "metric.get()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('accuracy', 0.8122)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGLDhXmicA27",
        "colab_type": "text"
      },
      "source": [
        "#Training Pytorchh Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rZJDwhZMCkO",
        "colab_type": "text"
      },
      "source": [
        "##Getting Dataset and Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhBBS4PfTu9C",
        "colab_type": "code",
        "outputId": "24ffdf44-30b1-411d-9f89-64852a83d58b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "normalize = pytorchT.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
        "\n",
        "train_transform = pytorchT.Compose([\n",
        "    pytorchT.RandomHorizontalFlip(),\n",
        "    pytorchT.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "val_transform = pytorchT.Compose([\n",
        "    pytorchT.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "pytorch_trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=train_transform)\n",
        "pytorch_trainloader = torch.utils.data.DataLoader(\n",
        "    pytorch_trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "pytorch_testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=val_transform)\n",
        "pytorch_testloader = torch.utils.data.DataLoader(\n",
        "    pytorch_testset, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAsHsduETu0P",
        "colab_type": "code",
        "outputId": "de43d119-dbe2-4f8d-89e6-6edb9c502921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "pytorch_criterion = pytorchnn.CrossEntropyLoss()\n",
        "pytorch_optimizer = pytorchoptim.Adam(pytorch.parameters(), 0.001)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 952 µs, sys: 0 ns, total: 952 µs\n",
            "Wall time: 960 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdh5Fz9Mdy07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bf3ac669-d22c-4110-8d5a-8b77d5a78ce0"
      },
      "source": [
        "%%time\n",
        "pytorch.train()\n",
        "for epoch in range(10):\n",
        "    for features, labels in pytorch_trainloader:\n",
        "        output = pytorch(features.cuda())\n",
        "        loss = pytorch_criterion(output, labels.cuda())\n",
        "        pytorch_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        pytorch_optimizer.step()        \n",
        "    print('Epoch:', epoch, 'done.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 done.\n",
            "Epoch: 1 done.\n",
            "Epoch: 2 done.\n",
            "Epoch: 3 done.\n",
            "Epoch: 4 done.\n",
            "Epoch: 5 done.\n",
            "Epoch: 6 done.\n",
            "Epoch: 7 done.\n",
            "Epoch: 8 done.\n",
            "Epoch: 9 done.\n",
            "CPU times: user 3min 31s, sys: 29.8 s, total: 4min 1s\n",
            "Wall time: 4min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX0uO2Vmfehi",
        "colab_type": "code",
        "outputId": "4e47cb39-c946-4412-8803-8b992fa82c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "pytorch.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in pytorch_testloader:\n",
        "        outputs = pytorch(features.cuda())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.cuda()).sum().item()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.02 s, sys: 373 ms, total: 1.39 s\n",
            "Wall time: 2.76 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwgzIEPJfiuv",
        "colab_type": "text"
      },
      "source": [
        "###I've taken the above code from the official tutorials by pytorch from thier website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FAyoGLglL6c",
        "colab_type": "code",
        "outputId": "6b89b7b0-94bf-4f46-a557-484956c8c19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Test Accuracy:', correct / total)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYZVpfN_fwme",
        "colab_type": "text"
      },
      "source": [
        "#Conclusion:\n",
        "\n",
        "*   MXNet's model took 2mins 43 secs!\n",
        "*   Pytorch's model took 4mins 9 secs!\n",
        "*   MXNet's model Test Accuracy: 81.2%\n",
        "*   Pytorch's model Test Accuracy: 79.6%\n",
        "----\n",
        "##So according to this benchmark, it looks like MXNet is over 1.5x faster than Pytorch.\n",
        "\n",
        "I think test accuracies of both models may vary with different training runs, because training depends on one important facter which is shuffling the data.... which happens randomly. So the point is that MXNet's model test accuracy would be always greater than Pytorch's model is clearly a worng statement."
      ]
    }
  ]
}