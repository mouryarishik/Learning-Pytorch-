{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch - Cifar10.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaCl69xdE_4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "73ee2847-133e-4ea2-c6fc-9ea5576946b7"
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euZwrRWnEqtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import tarfile\n",
        "import pickle\n",
        "import subprocess\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCHSIZE = 64\n",
        "LR = 0.01\n",
        "MOMENTUM = 0.9\n",
        "N_CLASSES = 10\n",
        "GPU = True\n",
        "\n",
        "if sys.version_info.major == 2:\n",
        "    # Backward compatibility with python 2.\n",
        "    from six.moves import urllib\n",
        "    urlretrieve = urllib.request.urlretrieve\n",
        "else:\n",
        "    from urllib.request import urlretrieve\n",
        "\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        out_str = subprocess.run([\"nvidia-smi\", \"--query-gpu=gpu_name\", \"--format=csv\"], stdout=subprocess.PIPE).stdout\n",
        "        out_list = out_str.decode(\"utf-8\").split('\\n')\n",
        "        out_list = out_list[1:-1]\n",
        "        return out_list\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "def get_cuda_version():\n",
        "    \"\"\"Get CUDA version\"\"\"\n",
        "    if sys.platform == 'win32':\n",
        "        raise NotImplementedError(\"Implement this!\")\n",
        "        # This breaks on linux:\n",
        "        #cuda=!ls \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\"\n",
        "        #path = \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\\" + str(cuda[0]) +\"\\\\version.txt\"\n",
        "    elif sys.platform == 'linux' or sys.platform == 'darwin':\n",
        "        path = '/usr/local/cuda/version.txt'\n",
        "    else:\n",
        "        raise ValueError(\"Not in Windows, Linux or Mac\")\n",
        "    if os.path.isfile(path):\n",
        "        with open(path, 'r') as f:\n",
        "            data = f.read().replace('\\n','')\n",
        "        return data\n",
        "    else:\n",
        "        return \"No CUDA in this machine\"\n",
        "\n",
        "def get_cudnn_version():\n",
        "    \"\"\"Get CUDNN version\"\"\"\n",
        "    if sys.platform == 'win32':\n",
        "        raise NotImplementedError(\"Implement this!\")\n",
        "        # This breaks on linux:\n",
        "        #cuda=!ls \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\"\n",
        "        #candidates = [\"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\\" + str(cuda[0]) +\"\\\\include\\\\cudnn.h\"]\n",
        "    elif sys.platform == 'linux':\n",
        "        candidates = ['/usr/include/x86_64-linux-gnu/cudnn_v[0-99].h',\n",
        "                      '/usr/local/cuda/include/cudnn.h',\n",
        "                      '/usr/include/cudnn.h']\n",
        "    elif sys.platform == 'darwin':\n",
        "        candidates = ['/usr/local/cuda/include/cudnn.h',\n",
        "                      '/usr/include/cudnn.h']\n",
        "    else:\n",
        "        raise ValueError(\"Not in Windows, Linux or Mac\")\n",
        "    for c in candidates:\n",
        "        file = glob.glob(c)\n",
        "        if file: break\n",
        "    if file:\n",
        "        with open(file[0], 'r') as f:\n",
        "            version = ''\n",
        "            for line in f:\n",
        "                if \"#define CUDNN_MAJOR\" in line:\n",
        "                    version = line.split()[-1]\n",
        "                if \"#define CUDNN_MINOR\" in line:\n",
        "                    version += '.' + line.split()[-1]\n",
        "                if \"#define CUDNN_PATCHLEVEL\" in line:\n",
        "                    version += '.' + line.split()[-1]\n",
        "        if version:\n",
        "            return version\n",
        "        else:\n",
        "            return \"Cannot find CUDNN version\"\n",
        "    else:\n",
        "        return \"No CUDNN in this machine\"\n",
        "\n",
        "\n",
        "\n",
        "def read_batch(src):\n",
        "    '''Unpack the pickle files\n",
        "    '''\n",
        "    with open(src, 'rb') as f:\n",
        "        if sys.version_info.major == 2:\n",
        "            data = pickle.load(f)\n",
        "        else:\n",
        "            data = pickle.load(f, encoding='latin1')\n",
        "    return data\n",
        "\n",
        "\n",
        "def shuffle_data(X, y):\n",
        "    s = np.arange(len(X))\n",
        "    np.random.shuffle(s)\n",
        "    X = X[s]\n",
        "    y = y[s]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def yield_mb(X, y, batchsize=64, shuffle=False):\n",
        "    if shuffle:\n",
        "        X, y = shuffle_data(X, y)\n",
        "    # Only complete batches are submitted\n",
        "    for i in range(len(X) // batchsize):\n",
        "        yield X[i * batchsize:(i + 1) * batchsize], y[i * batchsize:(i + 1) * batchsize]\n",
        "\n",
        "def process_cifar():\n",
        "    '''Load data into RAM'''\n",
        "    print('Preparing train set...')\n",
        "    train_list = [read_batch('./cifar-10-batches-py/data_batch_{0}'.format(i + 1)) for i in range(5)]\n",
        "    x_train = np.concatenate([t['data'] for t in train_list])\n",
        "    y_train = np.concatenate([t['labels'] for t in train_list])\n",
        "    print('Preparing test set...')\n",
        "    tst = read_batch('./cifar-10-batches-py/test_batch')\n",
        "    x_test = tst['data']\n",
        "    y_test = np.asarray(tst['labels'])\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "def maybe_download_cifar(src=\"https://ikpublictutorial.blob.core.windows.net/deeplearningframeworks/cifar-10-python.tar.gz\"):\n",
        "    '''Load the training and testing data\n",
        "    Mirror of: http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "    '''\n",
        "    try:\n",
        "        return process_cifar()\n",
        "    except:\n",
        "        # Catch the exception that file doesn't exist\n",
        "        # Download\n",
        "        print('Data does not exist. Downloading ' + src)\n",
        "        fname, h = urlretrieve(src, './delete.me')\n",
        "        print('Extracting files...')\n",
        "        with tarfile.open(fname) as tar:\n",
        "            tar.extractall()\n",
        "        os.remove(fname)\n",
        "        return process_cifar()\n",
        "\n",
        "\n",
        "def cifar_for_library(channel_first=True, one_hot=False):\n",
        "    # Raw data\n",
        "    x_train, x_test, y_train, y_test = maybe_download_cifar()\n",
        "    # Scale pixel intensity\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "    # Reshape\n",
        "    x_train = x_train.reshape(-1, 3, 32, 32)\n",
        "    x_test = x_test.reshape(-1, 3, 32, 32)\n",
        "    # Channel last\n",
        "    if not channel_first:\n",
        "        x_train = np.swapaxes(x_train, 1, 3)\n",
        "        x_test = np.swapaxes(x_test, 1, 3)\n",
        "    # One-hot encode y\n",
        "    if one_hot:\n",
        "        y_train = np.expand_dims(y_train, axis=-1)\n",
        "        y_test = np.expand_dims(y_test, axis=-1)\n",
        "        enc = OneHotEncoder(categorical_features='all')\n",
        "        fit = enc.fit(y_train)\n",
        "        y_train = fit.transform(y_train).toarray()\n",
        "        y_test = fit.transform(y_test).toarray()\n",
        "    # dtypes\n",
        "    x_train = x_train.astype(np.float32)\n",
        "    x_test = x_test.astype(np.float32)\n",
        "    y_train = y_train.astype(np.int32)\n",
        "    y_test = y_test.astype(np.int32)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJudk9m9EsiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "import torch.nn.init as init\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6l8Xuq7Euqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "29bcd46c-3fdf-48bb-945f-bcbf2b2c232e"
      },
      "source": [
        "print(\"OS: \", sys.platform)\n",
        "print(\"Python: \", sys.version)\n",
        "print(\"PyTorch: \", torch.__version__)\n",
        "print(\"Numpy: \", np.__version__)\n",
        "print(\"GPU: \", get_gpu_name())\n",
        "print(get_cuda_version())\n",
        "print(\"CuDNN Version \", get_cudnn_version())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OS:  linux\n",
            "Python:  3.6.7 (default, Oct 22 2018, 11:32:17) \n",
            "[GCC 8.2.0]\n",
            "PyTorch:  1.1.0\n",
            "Numpy:  1.14.6\n",
            "GPU:  ['Tesla T4']\n",
            "CUDA Version 10.0.130\n",
            "CuDNN Version  7.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGy0qeP7FRNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ed26a1d1-abef-4b41-ba05-16fd6997bf6c"
      },
      "source": [
        "x_train, x_test, y_train, y_test = cifar_for_library(channel_first = True)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing train set...\n",
            "Preparing test set...\n",
            "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000,) (10000,)\n",
            "float32 float32 int32 int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwSkF2jQEutR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class create_pytorch_model(nn.Module):\n",
        "    def __init__(self, n_classes=N_CLASSES):\n",
        "        super(create_pytorch_model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 50, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(50, 50, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(50, 100, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(100, 100, kernel_size=3, padding=1)\n",
        "        # feature map size is 8*8 by pooling\n",
        "        self.fc1 = nn.Linear(100*8*8, 512)\n",
        "        self.fc2 = nn.Linear(512, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # PyTorch requires a flag for training in dropout\n",
        "        x = self.conv2(F.relu(self.conv1(x)))\n",
        "        x = F.relu(F.max_pool2d(x, kernel_size=2, stride=2))\n",
        "        x = F.dropout(x, 0.25, training=self.training)\n",
        "\n",
        "        x = self.conv4(F.relu(self.conv3(x)))\n",
        "        x = F.relu(F.max_pool2d(x, kernel_size=2, stride=2))\n",
        "        x = F.dropout(x, 0.25, training=self.training)\n",
        "\n",
        "        x = x.view(-1, 100*8*8)   # reshape Variable\n",
        "        x = F.dropout(F.relu(self.fc1(x)), 0.5, training=self.training)\n",
        "        return self.fc2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiD9L8gvEu0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1ff9539b-8fc4-4e95-d9e0-eefbab7b37da"
      },
      "source": [
        "%%time\n",
        "model = create_pytorch_model().cuda()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 28.3 ms, sys: 9.2 ms, total: 37.5 ms\n",
            "Wall time: 38.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr6eZf9CEu21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b5d5527-55aa-42ca-b627-abbeb5b9acc1"
      },
      "source": [
        "%%time\n",
        "optimizer = optim.SGD(model.parameters(), LR, MOMENTUM)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 140 µs, sys: 98 µs, total: 238 µs\n",
            "Wall time: 241 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BaT0V0uEu5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "eda4f298-7fef-47b9-99c5-d143d90e8698"
      },
      "source": [
        "%%time\n",
        "model.train()\n",
        "for j in range(EPOCHS):\n",
        "    for data, target in yield_mb(x_train, y_train, BATCHSIZE, shuffle=True):\n",
        "        data = Variable(torch.FloatTensor(data).cuda())\n",
        "        target = Variable(torch.LongTensor(target).cuda())\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch %d' % (j))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "CPU times: user 1min 21s, sys: 49.2 s, total: 2min 10s\n",
            "Wall time: 2min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVSf0srZE7Jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0792918a-247d-4ba3-81db-a1654c6f3252"
      },
      "source": [
        "%%time\n",
        "model.eval() # Sets training = False\n",
        "n_samples = (y_test.shape[0]//BATCHSIZE)*BATCHSIZE\n",
        "y_guess = np.zeros(n_samples, dtype=np.int)\n",
        "y_truth = y_test[:n_samples]\n",
        "c = 0\n",
        "for data, target in yield_mb(x_test, y_test, BATCHSIZE):\n",
        "    output = model(Variable(torch.FloatTensor(data).cuda()))\n",
        "    pred = output.data.max(1)[1].cpu().numpy().squeeze()\n",
        "    y_guess[c*BATCHSIZE:(c+1)*BATCHSIZE] = pred\n",
        "    c += 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 370 ms, sys: 194 ms, total: 564 ms\n",
            "Wall time: 569 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbfwO1YhE7Ln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a383219-8e99-4769-e053-5821c698272e"
      },
      "source": [
        "print(\"Accuracy: \", 1.*sum(y_guess == y_truth)/len(y_guess))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7755408653846154\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}